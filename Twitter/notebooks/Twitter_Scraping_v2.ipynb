{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Project Roadmap\n",
    "\n",
    "1. Import Project Libraries\n",
    "\n",
    "2. Key and Authentication\n",
    "\n",
    "3. Scrape Twitter\n",
    "\n",
    "4. Place into a DataFrame\n",
    "\n",
    "5. Save Twitter corpus to a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Project Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tweepy\n",
    "import requests\n",
    "import json\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "import spacy\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key and Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "authentication_file = pd.read_excel('authentication_file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secret keys and authentication\n",
    "\n",
    "consumer_api_key = authentication_file['consumer_api_key']\n",
    "consumer_api_secret_key = authentication_file['consumer_api_secret_key']\n",
    "access_token = authentication_file['access_token']\n",
    "access_token_secret = authentication_file['access_token_secret']\n",
    "BEARER_TOKEN = authentication_file['bearer_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_api_key, consumer_api_secret_key)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# The last command prints a message and waits if the rate limit is exceeded\n",
    "# Twitter allows 15 requests per application per 15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list to append tweet data to\n",
    "attributes_container = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each tweet scraping code and sleep for 30 seconds\n",
    "for x in range(23):\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#IranProtests2022').get_items()):\n",
    "        if i>150:\n",
    "            break\n",
    "        attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#IranRevoIution2022').get_items()):\n",
    "        if i>150:\n",
    "            break\n",
    "        attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(' Hijab').get_items()):\n",
    "        if i>150:\n",
    "            break\n",
    "        attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#IranProtests').get_items()):\n",
    "        if i>150:\n",
    "            break\n",
    "        attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#FreeIran').get_items()):\n",
    "        if i>150:\n",
    "            break\n",
    "        attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])    \n",
    "    \n",
    "    # Print number iteration\n",
    "    print(f'Number {x} sleeping')\n",
    "    print(\"Data collected: \", len(attributes_container))\n",
    "    time.sleep(30)\n",
    "\n",
    "print(len(attributes_container))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commenting out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "# for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#IranProtests2022').get_items()):\n",
    "#     if i>150:\n",
    "#         break\n",
    "#     attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "# print(len(attributes_container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#IranRevoIution2022').get_items()):\n",
    "#     if i>150:\n",
    "#         break\n",
    "#     attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "# print(len(attributes_container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,tweet in enumerate(sntwitter.TwitterSearchScraper('Hijab').get_items()):\n",
    "#     if i>150:\n",
    "#         break\n",
    "#     attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "# print(len(attributes_container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(23):\n",
    "#     for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#FreeIran').get_items()):\n",
    "#         if i>150:\n",
    "#             break\n",
    "#         attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "#     # Print number iteration\n",
    "#     print(f'Number {x} sleeping')\n",
    "#     print(\"Data collected: \", len(attributes_container))\n",
    "#     time.sleep(30)\n",
    "\n",
    "# print(len(attributes_container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(23):\n",
    "#     for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#IranProtests').get_items()):\n",
    "#         if i>150:\n",
    "#             break\n",
    "#         attributes_container.append([tweet.id, tweet.user.username, tweet.date, tweet.likeCount, tweet.replyCount, tweet.retweetCount, tweet.sourceLabel, tweet.content])\n",
    "#     # Print number iteration\n",
    "#     print(f'Number {x} sleeping')\n",
    "#     print(\"Data collected: \", len(attributes_container))\n",
    "#     time.sleep(30)\n",
    "\n",
    "# print(len(attributes_container))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to load the list\n",
    "tweets_df = pd.DataFrame(attributes_container, columns=[\"Tweet ID\", \"User\", \"Date Created\", \"Number of Likes\", \"Number of Replies\", \"Number of Retweets\", \"Source of Tweet\", \"Tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6946\n",
      "6946\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets_df))\n",
    "tweets_df.drop_duplicates()\n",
    "print(len(tweets_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Twitter corpus to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df.to_csv(r'D:\\Shyam\\Documents\\02 - USF\\NLP\\tweets_data_new_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Python_v3_9_13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4b639b753c6fa34c83f549dd8821199fbc408c013b931bda3b465c931d17a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
